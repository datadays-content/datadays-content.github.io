{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<body  style=\"background-color:rgb(11, 42, 73);\">\n",
    "    <div style=\"direction:rtl;line-height:300%;background-color:rgb(11, 42, 73);\">\n",
    "            <img src=\"./figs/Logo Final.jpg\" style=\"position:reletive;margin-top:15pt;float:right;background-color:rgb(11, 42, 73);\" width=\"200\" height=\"200\"/>\n",
    "    <img src=\"./figs/Sharif Logo.png\" style=\"position:reletive;margin-top:25pt;margin-left:20pt;float:left;background-color:rgb(11, 42, 73);\" width=\"170\" height=\"170\"/>\n",
    "\t\t<div align=center>\n",
    "\t\t\t<font face=\"IranNastaliq\" size=30 color=white>\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t\t<p></p>\n",
    "                <br>\n",
    "به نام خدا\n",
    "\t\t\t\t<p></p>\n",
    "\t\t\t</font>\n",
    "\t\t</div>\n",
    "        \t\t\t<div align=center style=\"color:white\">\n",
    "                        <font size=50 face=\"XB Niloofar\">\n",
    "                            <br>\n",
    "                           تحلیل داده‌های متن\n",
    "                        </font>\n",
    "            </div>\n",
    "    </div>\n",
    "</body>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<hr />\n",
    "\t\t<style type=\"text/css\" scoped>\n",
    "        p{\n",
    "        border: 1px solid #a2a9b1;background-color: #f8f9fa;display: inline-block;\n",
    "        };\n",
    "        </style>\n",
    "\t\t<div>\n",
    "\t\t\t<h3 style=\"color:#0051A2\">فهرست مطالب</h3>\n",
    "\t\t\t<ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                    <a href=\"#sec_tidy_data\">\n",
    "مرتب‌سازی داده\n",
    "                    </a>              \n",
    "                </li>\n",
    "                <ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                    <a href=\"#sec_why_tidy_data\">\n",
    "چرا باید داده را مرتب کنیم؟ \n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_tidytext_install\">\n",
    "نصب کتابخانه‌ی tidytext \n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_unnest_tokens\">\n",
    "تابع unnest_tokens \n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_tidy_shahname\">\n",
    "یک قدم فراتر: بررسی چند بخش شاهنامه\n",
    "                    </a>              \n",
    "                </li>\n",
    "                </ul>\n",
    "                 <li>\n",
    "                    <a href=\"#sec_analysis_freq\">\n",
    " تحلیل متن با استفاده از فراوانی\n",
    " </a>              \n",
    "                </li>\n",
    "                <ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                    <a href=\"#sec_tfidf\">\n",
    "تعریف معیار tf-idf \n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_tfidf_R\">\n",
    "پیاده‌سازی tf-idf در R                    </a>              \n",
    "                </li>\n",
    "\t\t\t</ul>\n",
    "                <li>\n",
    "                    <a href=\"#sec_analysis_cors\">\n",
    "تحلیل متن با استفاده از رابطه‌ی بین کلمات\n",
    "                    </a>              \n",
    "                </li>\n",
    "                <ul style=\"margin-right: 0;\">\n",
    "\t\t\t\t<li>\n",
    "                    <a href=\"#sec_ngrams\">\n",
    "تعریف n-گرام\n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_ngrams_R\">\n",
    "بدست آوردن n-گرام‌ها در R \n",
    "                    </a>              \n",
    "                </li>\n",
    "                <li>\n",
    "                    <a href=\"#sec_ngrams_tfidf\">\n",
    "تحلیل n-گرام‌ها با استفاده از tf-idf                    </a>              \n",
    "                </li>\n",
    "\t\t\t</ul>\n",
    "\t\t\t</ul>\n",
    "\t\t</div>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sec_tidy_data\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=7>\n",
    "\t\t<font style=\"color:#0051A2\" size=6>\n",
    "\t\t\t<br />\n",
    "            <hr>\n",
    "\t\t\t<div align=center><b>\n",
    "مرتب‌سازی داده\n",
    "                </b> </div>\n",
    "\t\t</font>\n",
    "\t\t<hr>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_why_tidy_data\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "چرا باید داده را مرتب کنیم؟\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        \tهنگامی که با تحلیل داده سر و کار داریم، اکثر مواقع داده‌ی در دست، داده‌ای نامرتب و به هم‌ریخته است. در قدم اول کاری که تحلیل را آسان‌تر و کاراتر می‌کند تمیز کردن و ساختار دادن به داده است. در کار با داده‌های متنی نیز ابتدا باید آن‌ را به نحوی مرتب کنیم که نیازهای ما را برآورده کند.\n",
    "        <br><br>\n",
    "        <a href=\"https://www.jstatsoft.org/article/view/v059i10\">این مقاله</a>\n",
    "داده‌ی مرتب را داده‌ای با ویژگی‌های زیر تعریف می‌کند:\n",
    "        <ol>\n",
    "            <li>\n",
    "               هر متغیر یک ستون است.  \n",
    "            </li>\n",
    "            <li>\n",
    "                هر مشاهده یک سطر است. \n",
    "            </li>            \n",
    "            <li>\n",
    "                هر مدل از واحد مشاهده یک جدول است. \t\n",
    "            </li>\n",
    "            </ol>\n",
    "        <br>\n",
    "برای داده‌های متنی، مدل تمیز شده را جدولی با یک \n",
    "        <i>token</i>\n",
    "         در هر سطر تعریف می‌کنیم. یک token، واحد معناداری از متن است (مثلا یک کلمه یا یک جمعه) که ما برای تحلیل از آن استفاده می‌کنیم. در مرتب‌سازی داده‌های متنی، تلاش می‌کنیم که طی فرآیند\n",
    "        <i>tokenization</i>\n",
    "        متن را به tokenها تقسیم کنیم. \n",
    "<br><br>\n",
    "پس از این مقدمه و تعاریف، پیاده‌سازی این عملیات در R را شروع می‌کنیم. \n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_tidytext_install\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "نصب کتاب‌خانه‌ی tidytext\n",
    "</font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        با استفاده از یکی از دو روش زیر، کتابخانه‌ی tidytext را نصب کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "also installing the dependencies ‘SnowballC’, ‘hunspell’, ‘tokenizers’\n",
      "\n",
      "Warning message in install.packages(\"tidytext\"):\n",
      "“installation of package ‘SnowballC’ had non-zero exit status”Warning message in install.packages(\"tidytext\"):\n",
      "“installation of package ‘hunspell’ had non-zero exit status”Warning message in install.packages(\"tidytext\"):\n",
      "“installation of package ‘tokenizers’ had non-zero exit status”Warning message in install.packages(\"tidytext\"):\n",
      "“installation of package ‘tidytext’ had non-zero exit status”Updating HTML index of packages in '.Library'\n",
      "Making 'packages.html' ... done\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in library(devtools): there is no package called ‘devtools’\n",
     "output_type": "error",
     "traceback": [
      "Error in library(devtools): there is no package called ‘devtools’\nTraceback:\n",
      "1. library(devtools)",
      "2. stop(txt, domain = NA)"
     ]
    }
   ],
   "source": [
    "# روش اول\n",
    "install.packages(\"tidytext\")\n",
    "\n",
    "# روش دوم\n",
    "library(devtools)\n",
    "install_github(\"juliasilge/tidytext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "پس از اتمام فرآیند نصب، با اجرای دستور زیر می‌توانید از آن استفاده کنید.\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidytext)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_unnest_tokens\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "تابع unnest_tokens\n",
    "</font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "داده‌ی ساده‌ي زیر شامل چند بیت آغاز شاهنامه‌ی فردوسی است.\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "df <- data_frame(text = c(\"به نام خداوند جان و خرد\", \n",
    "       \"کزین برتر اندیشه برنگذرد\",\n",
    "       \"خداوند نام و خداوند جای\",\n",
    "       \"خداوند روزی ده رهنمای\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "        می‌خواهیم این دیتافریم را طبق تعریفی که قبلا ارائه کردیم tokenize کنیم. تابع $\\texttt{unnest_tokens()}$ به شکل بسیار راحتی این کار را برای ما می‌کند. این تابع ورودی‌های زیر را می‌گیرد:\n",
    "        <ol>\n",
    "    <li>\n",
    "        دیتافریمی که باید tokenize کند. \n",
    "    </li>\n",
    "        <li>\n",
    "            نام ستون خروجی شامل tokenها\n",
    "    </li>\n",
    "        <li>\n",
    "            نام ستون ورودی شامل متن\n",
    "    </li>\n",
    "        <li>\n",
    "            نوع token \n",
    "    </li>\n",
    "    </ol>\n",
    "        تا اینجا مورد اول تا سوم برای ما کافی هستند، در رابطه با مورد چهارم جلوتر توضیح خواهیم داد. \n",
    "مطابق با توضیحات بالا، تابع را فراخوانی می‌کنیم\n",
    "\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df %>% unnest_tokens(word, text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "        می‌بینید که در ستون خروجی word، کلمات جداشده‌ی متن قرار دارند. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_tidy_shahname\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "یک قدم فراتر: بررسی چند بخش شاهنامه\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "داده‌ي موجود در فایل sample.txt شامل ۱۰ بخش اول داستان رستم و اسفندیار شاهنامه است. با دستور زیر داده را می‌خوانیم.    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rostam_esfandiar <- read.delim(file = \"sample.txt\", stringsAsFactors = F, header = F)\n",
    "colnames(rostam_esfandiar) = \"beyt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "پس از بررسی داده، متوجه می‌شویم که شروع هر بخش با «*بخش n*» مشخص شده است که n عدد با فونت فارسی است. می‌خواهیم بخش‌های مختلف کتاب را از هم جدا کنیم. به regex زیر توجه کنید:\n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "regex_chapter <- \"بخش [۰۱۲۳۴۵۶۷۸۹]+\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "این regex تشخیص می‌دهد که «بخش n» در متن قرار دارد یا نه. برای اطلاعات بیشتر از regexها به         <a href=\"http://www.cbs.dtu.dk/courses/27610/regular-expressions-cheat-sheet-v2.pdf\">اینجا</a>\n",
    "        و \n",
    "         <a href=\"https://stringr.tidyverse.org/articles/regular-expressions.html\">اینجا</a>\n",
    "        مراجعه کنید. \n",
    "        <br><br>\n",
    "        با استفاده از دستورات زیر مشخص می‌کنیم که هر بیت مربوط به کدام بخش است:\n",
    "       \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(stringr)\n",
    "rostam_esfandiar <- rostam_esfandiar %>%\n",
    "    mutate(chapter = cumsum(str_detect(beyt, regex_chapter)))\n",
    "rostam_esfandiar %>% sample_n(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "        مانند فرآیندی که در بخش قبل انجام دادیم، کلمات را جدا کرده، تعداد آن ها در هر فصل را بدست می‌آوریم و به ترتیب نزولی می‌چینیم. \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rostam_esfandiar <- rostam_esfandiar %>% \n",
    "    unnest_tokens(word, beyt) %>% \n",
    "    group_by(chapter, word) %>% \n",
    "    summarise(count = n()) %>% \n",
    "    arrange(chapter, desc(count))\n",
    "rostam_esfandiar %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\tدر هر بخش ۱۰ کلمه‌ی پر‌تکرار را انتخاب می‌کنیم \n",
    "</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rostam_esfandiar.top10 <- rostam_esfandiar %>% \n",
    "  mutate(rank = rank(-count) %>% as.integer(), \n",
    "         rank = row_number(rank)) %>% \n",
    "  filter(rank <= 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\tدر نهایت نمودار فراوانی این کلمات را رسم می‌کنیم</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "p <- ggplot(rostam_esfandiar.top10, aes(x = reorder(word, -count), y = count, fill = as.factor(paste(\"بخش\", chapter, sep = \" \")))) + \n",
    "  geom_bar(stat = \"identity\", show.legend = FALSE) + \n",
    "  facet_wrap(~chapter, ncol = 5,  scales = \"free\") + \n",
    "  theme_minimal() + \n",
    "  theme(axis.title.x = element_blank(), axis.title.y = element_blank()) + \n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\tچون ggplot برای زبان‌های راست به چپ درست عمل نمی‌کند از کتابخانه‌ی plotly استفاده می‌کنیم. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library(plotly)\n",
    "ggplotly(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sec_analysis_freq\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=7>\n",
    "\t\t<font style=\"color:#0051A2\" size=6>\n",
    "\t\t\t<br />\n",
    "            <hr>\n",
    "\t\t\t<div align=center><b>\n",
    "تحلیل متن با استفاده از فراوانی \n",
    "                </b> </div>\n",
    "\t\t</font>\n",
    "\t\t<hr>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_tfidf\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    " تعریف معیار tf-idf\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        \tاولین معیاری که برای میزان مهم بودن یک کلمه به ذهن می‌رسد این است که تعداد دفعات استفاده از آن را در نظر بگیریم. ولی در قسمت قبل دیدیم که با این کار تعداد زیادی کلمات بی‌معنی به عنوان کلمات مهم انتخاب می‌شوند. شاید وسوسه شویم که لیستی از کلمات اضافه و بی‌معنی تعریف کنیم و این کلمات را از متن حذف کنیم. ولی این کار، حرفه‌ای نیست و لزوما نتایج درستی به همراه نخواهد داشت. \n",
    "        <br><br>\n",
    "        فرض کنید میخواهیم کلمات مهم هر فصل‌ شاهنامه را استخراج کنیم. در واقع ما به دنبال کلماتی هستیم که علاوه بر اینکه در یک فصل زیاد تکرار شده‌اند در فصول دیگر زیاد استفاده نشده باشد. بدین منظور دو معیار زیر را تعریف می‌کنیم:\n",
    "        <ul>\n",
    "            <li>\n",
    "                معیار $\\text{TF(Term Frequency)}$: \n",
    "                    تعداد دفعات تکرار این کلمه در مستند به تعداد کل کلمات مستند\n",
    "                <br><br>\n",
    "                $$tf(term) = \\frac{n_{term~in~document}}{n_{total~ document~words}}$$</li><br><br>\n",
    "            <li>\n",
    "                            معیار $\\text{IDF(Inverse Document Frequency)}$:\n",
    "    لگاریتم طبیعی معکوس تعداد مستندات شامل این کلمه به تعداد کل مستندات. \n",
    "$$idf(term) = ln\\Big(\\frac{n_{documents}}{n_{documents~containing~term}}\\Big)$$\n",
    "            </li>\n",
    "        </ul>\n",
    "        <br>\n",
    "        معیار tf-idf را ضرب این دو عدد تعریف می‌کنیم. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_tfidf_R\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "پیاده‌سازی tf-idf در R        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "تابع \n",
    "        $\\texttt{bind_tf_idf}$        در کتابخانه‌ی tidytext این معیار‌ها را به سادگی محاسبه می‌کند. این تابع ورودی‌های زیر را می‌گیرد:\n",
    "    <ol>\n",
    "        <li>دیتافریمی که باید بررسی کند.  </li>\n",
    "        <li> نام ستون ورودی شامل tokenها </li>\n",
    "        <li> نام ستون ورودی شامل نام مستندات</li>\n",
    "        <li>نام ستون ورودی شامل تعداد دفعاتی که هر token در مستند مربوطه تکرار شده‌است. </li>\n",
    "        </ol>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "می‌خواهیم عملکرد این تابع را بررسی کنیم. دیتافریم زیر، شامل ۱۰ بخش اول داستان‌های رستم و اسفندیار، سهراب، ضحاک، سیاوس و پادشاهی بهرام گور در شاهنامه‌ي فردوسی است. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "shahname <- read_csv(\"shahname.csv\")\n",
    "shahname %>% head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "        مطابق بخش اول، متن را tokenize می‌کنیم، تعداد دفعات تکرار هر کلمه در هرکتاب را بدست می‌آوریم. می‌بینید که کلماتی که از همه بیشتر تکرار شده‌اند بی‌معنی‌اند. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shahname.words <- shahname %>% \n",
    "    unnest_tokens(word, text) %>%\n",
    "    group_by(book, word) %>% \n",
    "    summarise(count = n())\n",
    "shahname.words %>% arrange(book, desc(count)) %>% head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "حال از تابع\n",
    "        $\\texttt{bind_tf_idf}$\n",
    "        استفاده می‌کنیم. می‌بینید که کلمات با tf-idf بالاتر از لحاظ منطقی بامعنا‌ترند.    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shahname.words <- shahname.words %>% \n",
    "    bind_tf_idf(word, book, count) %>% \n",
    "    arrange(book, desc(tf_idf))\n",
    "shahname.words %>% head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "در نهایت نمودار ۱۰ کلمات\n",
    "        کلیدی\n",
    "هر فصل را رسم می‌کنیم. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.data <- shahname.words %>% \n",
    "  mutate(rank = rank(-tf_idf) %>% as.integer(), \n",
    "         rank = row_number(rank)) %>% \n",
    "  filter(rank <= 10) %>% arrange(book, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p <- ggplot(plot.data, aes(x = reorder(word, -tf_idf), y = tf_idf, fill = book)) + \n",
    "  geom_bar(stat = \"identity\", show.legend = FALSE) + \n",
    "  facet_wrap(~book, ncol = 2,  scales = \"free\") + \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ggplotly(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div id=\"sec_analysis_cors\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Zar\" size=7>\n",
    "\t\t<font style=\"color:#0051A2\" size=6>\n",
    "\t\t\t<br />\n",
    "            <hr>\n",
    "\t\t\t<div align=center><b>\n",
    "تحلیل متن با استفاده از رابطه‌ی بین کلمات            \n",
    "                </b></div>\n",
    "\t\t</font>\n",
    "\t\t<hr>\n",
    "\t</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_ngrams\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "تعریف n-گرام\n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        \tتا به حال کل کاری که برای تحلیل متن کردیم بررسی تک‌ تک کلمات یا رابطه‌شان با کل مستند بود. در حالی که برای تحلیل کامل و جامع تنها این کافی نیست. واضح است که کلمات بین خودشان نیز با هم رابطه دارند. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "واژه‌ي n-گرام به معنای کلمات nتایی متوالی موجود در متن است. برای مثال به مصراع زیر توجه کنید:\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "        <center>\n",
    "بسی رنج بردم در این سال سی\n",
    "        </center>\n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "عبارات «بسی رنج بردم»، «رنج بردم در»، «بردم در این»، «در این سال» و «این سال سی» ۳-گرام‌های آن هستند.\n",
    "        </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_ngrams_R\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "بدست آوردن n-گرام‌ها در R \n",
    "        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        حال نوبت آن رسیده است که ورودی چهارم تابع $\\texttt{unnest_tokens()}$، یعنی نوع tokenها را مورد بررسی قرار دهیم. \n",
    "    <br><br>\n",
    "        \tبرای اینکه بتوانیم n-گرام‌ها را با استفاده از این تابع بدست آوریم، باید علاوه بر ورودی‌های قبلی، گزینه‌ی$\\texttt{token = “ngrams”}$ را نیز به آن اضافه کنیم. هم‌چنین ورودی n در این تابع، بیانگر طول n-گرام‌هاست. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "\tبرای مثال سعی می‌کنیم ۲-گرام‌های متون شاهنامه‌ که در قسمت قبل نیز استفاده کردیم را بدست آوریم:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shahname.bigrams <- shahname %>% \n",
    "    unnest_tokens(bigram, text, token = \"ngrams\", n = 2)\n",
    "\n",
    "shahname.bigrams %>% head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "مانند قبل آن ها را بر حسب تعداد دفعات تکرار در هر فصل مرتب می‌کنیم:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shahname.bigrams <- shahname.bigrams %>% \n",
    "    group_by(book, bigram) %>% \n",
    "    summarise(count = n()) %>% \n",
    "    arrange(book, desc(count)) \n",
    "\n",
    "shahname.bigrams %>% arrange(book, desc(count)) %>%head(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "برخلاف تک‌کلمات که خیلی بی‌معنی بودند، این کلمات نسبتا با معنی‌ترند.\n",
    "        <br><br>\n",
    "        با استفاده از تابع\n",
    "        $\\texttt{separate\n",
    "        موجود در کتابخانه‌ی tidyr می‌توان این دو کلمه را از هم جدا کرد.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3\n",
    "shahname.bigrams %>% \n",
    "    separate(bigram, c(\"word1\", \"word2\"), sep = \" \") %>% \n",
    "    head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "            در صورتی که از این تابع استفاده کردید و پس از آن خواستید مجدد این دو کلمه را به هم بچسبانید می‌توانید، از تابع $\\texttt{unite()}$ استفاده کنید. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<div id=\"sec_ngrams_tfidf\" style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5>\n",
    "\t\t<font color=#006FDE size=6>\n",
    "تحلیل n-گرام‌ها با استفاده از tf-idf        </font>\n",
    "\t\t<p></p>\n",
    "\t\t<hr>\n",
    "        همانند تک‌کلمات که قبلا با tf-idf تحلیل کردیم، n-گرام‌ها را نیز می‌توان با این روش تحلیل کرد. \n",
    "    </font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "shahname.bigrams <- shahname.bigrams %>% \n",
    "    bind_tf_idf(bigram, book, count) %>% \n",
    "    arrange(book, desc(tf_idf))\n",
    "\n",
    "shahname.bigrams %>% head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"direction:rtl;line-height:300%;\">\n",
    "\t<font face=\"XB Niloofar\" size=5> \n",
    "نمودار ۱۰تای برتر را رسم می‌کنیم.        \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.data <- shahname.bigrams %>% \n",
    "    mutate(rank = rank(-tf_idf) %>% as.integer(), rank = row_number(rank)) %>% \n",
    "    filter(rank <= 10) %>% \n",
    "    arrange(book, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "p <- ggplot(plot.data, aes(x = reorder(bigram, -tf_idf), y = tf_idf, fill = book)) + \n",
    "  geom_bar(stat = \"identity\", show.legend = FALSE) + \n",
    "  facet_wrap(~book,scales = \"free\") + \n",
    "  theme_minimal() + \n",
    "  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1), \n",
    "        axis.title.x = element_blank(), axis.title.y = element_blank()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ggplotly(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
